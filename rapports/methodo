Méthodologie de Tests

a) Présentation de la collection CISI 

Les recherches se font au travers d'une collection de documents, ici nommé CISI. Cette collection est constituée des documents suivant : 

Un document nommé ALLnettoye contenant un ensemble d'articles textuels (ici 1460), qui sont chacun localisés par un nombre identifiant unique.
Un document nommé QRY contenant un ensemble de requêtes, chaque d'elles constituées d'un certain nombre de questions. Chaque requête est ici aussi localisé par un nombre identifiant unique.
Un autre nommé "motsvides", contenant les StopWords, un ensemble de mot à ignorer lors de la recherche dans les articles, pour ne tenir compte que des mots significatifs.
Enfin le document REL, qui contient la liste des articles attendus comme résultats à l'exécution de chaque requête. REL est constitué d'une liste d'associations "index requête - index article", 
faisant correspondre les requêtes avec leurs résultats. Cette liste a été réalisée par un ensemble d'experts et constitue donc l'objectif vers lequel nous essayons de faire converger nos propres 
résultats ; elle servira a évaluer par comparaison la qualité des résultats de notre algorithme d'indexation.

b) Critères d'indexation

Lors du passage des articles aux programme, Lucene indexe chacun des articles selon son contenu. Chacun des mots d'un article (excepté les StopWords) 
devient alors un index de l'article, ce qui permet par la suite à Lucene d'effectuer les interrogations à la base d'article selon des mots, sans avoir à lire l'intégralité des articles à chaque requête.   

Les recherches effectuées dans le cadre de ce projet sont faite de la manière suivante : Lucene interroge, pour chacune des requêtes de QRY, 
l'index des articles de ALLnettoye contenant des éléments de réponse. Le résultat de l'interrogation pour une requête est alors la liste des articles pour lesquels l'index a "matché" avec la requête. 
Lorsqu'un article est retenu, son identifiant est ajouté à l'index des résultats pour la requête correspondante. Le résultat de la recherche est donc constitué d'un index des articles liés à chaque ensemble de requêtes.

c) Évaluation de la qualité des résultats

L'évaluation de la qualité des résultats se fait au moyen de la classification des résultats retournés par l'algorithme. Un document comme peut être classifié selon 4 types selon la situation :

vrai positif (VP): un document attendu comme résultat, et qui a bien été retourné.
vrai négative (VN): un document non attendu comme résultat, et qui n'a en effet pas été retourné.

faux positif (FP): un document qui n'était pas attendu comme résultat, mais qui a été retourné malgré tout.
faux négatif (FN): un document attendu comme résultat, mais qui n'a pas été retourné.

Une fois la recherche effectuée, la pertinence des résultats est évaluée selon deux critères :

Le premier critère d'évaluation est le Recall, qui est un critère retournant la part d'articles retournés parmi la totalité des articles attendus.
Le formule donnant le Recall est donc : VP / (VP + FN). On fait ensuite la moyenne du Recall de chacune des requêtes, et l'on a ainsi la valeur du Recall pour la totalité des requêtes.

Le second critère d'évaluation des résultats est la Précision. La Précision est construite de la manière suivante : pour chacune des requêtes, on regarde la part de résultats attendus qui ont été retournés parmi le nombre de résultats obtenus. 
La formule donnant la Précision est donc : VP / (VP + FP). On fait alors la moyenne de ces valeurs pour chacune des requêtes, et l'on obtient ainsi la Précision de l'interrogation.

Ces deux critères, associés à la taille de l'index créé ainsi qu'aux temps nécessaires à la création des index pour les articles et à l'interrogation des index lors des requêtes, permettent de mesurer la qualité de la recherche, qui se mesure donc au travers des critères de Recall et de Précision.